{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/chiranthans23/toxic-comment-classsification/blob/master/toxic_comment_classification.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zDRP6kzJZ5Av"
      },
      "source": [
        "# **Part 1: Setup libraries**\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zvYaZUPrUspC",
        "outputId": "be75472a-bfed-45ba-a0b7-ff4e89e1e39b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tue Jan  4 19:28:44 2022       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 495.44       Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla K80           Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   70C    P0    74W / 149W |   1422MiB / 11441MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ],
      "source": [
        "!nvidia-smi\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Zf_VK9bXU3sf",
        "outputId": "82f2aed1-71a6-4629-9617-f9c8d26e4110"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torchtext==0.8.0 in /usr/local/lib/python3.7/dist-packages (0.8.0)\n",
            "Requirement already satisfied: torch==1.7.1 in /usr/local/lib/python3.7/dist-packages (1.7.1)\n",
            "Requirement already satisfied: pytorch-lightning==1.2.2 in /usr/local/lib/python3.7/dist-packages (1.2.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torchtext==0.8.0) (1.19.5)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from torchtext==0.8.0) (4.62.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from torchtext==0.8.0) (2.23.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch==1.7.1) (3.10.0.2)\n",
            "Requirement already satisfied: future>=0.17.1 in /usr/local/lib/python3.7/dist-packages (from pytorch-lightning==1.2.2) (0.18.2)\n",
            "Requirement already satisfied: PyYAML!=5.4.*,>=5.1 in /usr/local/lib/python3.7/dist-packages (from pytorch-lightning==1.2.2) (6.0)\n",
            "Requirement already satisfied: tensorboard>=2.2.0 in /usr/local/lib/python3.7/dist-packages (from pytorch-lightning==1.2.2) (2.7.0)\n",
            "Requirement already satisfied: fsspec[http]>=0.8.1 in /usr/local/lib/python3.7/dist-packages (from pytorch-lightning==1.2.2) (2021.11.1)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.7/dist-packages (from fsspec[http]>=0.8.1->pytorch-lightning==1.2.2) (3.8.1)\n",
            "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch-lightning==1.2.2) (0.12.0)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch-lightning==1.2.2) (1.8.0)\n",
            "Requirement already satisfied: protobuf>=3.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch-lightning==1.2.2) (3.17.3)\n",
            "Requirement already satisfied: grpcio>=1.24.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch-lightning==1.2.2) (1.42.0)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch-lightning==1.2.2) (1.0.1)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch-lightning==1.2.2) (3.3.6)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch-lightning==1.2.2) (1.35.0)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch-lightning==1.2.2) (0.37.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch-lightning==1.2.2) (0.6.1)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch-lightning==1.2.2) (57.4.0)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch-lightning==1.2.2) (0.4.6)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from absl-py>=0.4->tensorboard>=2.2.0->pytorch-lightning==1.2.2) (1.15.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard>=2.2.0->pytorch-lightning==1.2.2) (4.8)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard>=2.2.0->pytorch-lightning==1.2.2) (0.2.8)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard>=2.2.0->pytorch-lightning==1.2.2) (4.2.4)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard>=2.2.0->pytorch-lightning==1.2.2) (1.3.0)\n",
            "Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard>=2.2.0->pytorch-lightning==1.2.2) (4.8.2)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard>=2.2.0->pytorch-lightning==1.2.2) (3.6.0)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard>=2.2.0->pytorch-lightning==1.2.2) (0.4.8)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->torchtext==0.8.0) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->torchtext==0.8.0) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->torchtext==0.8.0) (2021.10.8)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->torchtext==0.8.0) (2.10)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard>=2.2.0->pytorch-lightning==1.2.2) (3.1.1)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.7/dist-packages (from aiohttp->fsspec[http]>=0.8.1->pytorch-lightning==1.2.2) (1.2.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.7/dist-packages (from aiohttp->fsspec[http]>=0.8.1->pytorch-lightning==1.2.2) (1.2.0)\n",
            "Requirement already satisfied: asynctest==0.13.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->fsspec[http]>=0.8.1->pytorch-lightning==1.2.2) (0.13.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->fsspec[http]>=0.8.1->pytorch-lightning==1.2.2) (21.2.0)\n",
            "Requirement already satisfied: charset-normalizer<3.0,>=2.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->fsspec[http]>=0.8.1->pytorch-lightning==1.2.2) (2.0.8)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->fsspec[http]>=0.8.1->pytorch-lightning==1.2.2) (1.7.2)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.7/dist-packages (from aiohttp->fsspec[http]>=0.8.1->pytorch-lightning==1.2.2) (5.2.0)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.7/dist-packages (from aiohttp->fsspec[http]>=0.8.1->pytorch-lightning==1.2.2) (4.0.2)\n",
            "Requirement already satisfied: wandb in /usr/local/lib/python3.7/dist-packages (0.12.9)\n",
            "Requirement already satisfied: subprocess32>=3.5.3 in /usr/local/lib/python3.7/dist-packages (from wandb) (3.5.4)\n",
            "Requirement already satisfied: sentry-sdk>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (1.5.1)\n",
            "Requirement already satisfied: psutil>=5.0.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (5.4.8)\n",
            "Requirement already satisfied: docker-pycreds>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (0.4.0)\n",
            "Requirement already satisfied: pathtools in /usr/local/lib/python3.7/dist-packages (from wandb) (0.1.2)\n",
            "Requirement already satisfied: shortuuid>=0.5.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (1.0.8)\n",
            "Requirement already satisfied: six>=1.13.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (1.15.0)\n",
            "Requirement already satisfied: configparser>=3.8.1 in /usr/local/lib/python3.7/dist-packages (from wandb) (5.2.0)\n",
            "Requirement already satisfied: GitPython>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (3.1.24)\n",
            "Requirement already satisfied: Click!=8.0.0,>=7.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (7.1.2)\n",
            "Requirement already satisfied: promise<3,>=2.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (2.3)\n",
            "Requirement already satisfied: requests<3,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (2.23.0)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.7/dist-packages (from wandb) (6.0)\n",
            "Requirement already satisfied: yaspin>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (2.1.0)\n",
            "Requirement already satisfied: protobuf>=3.12.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (3.17.3)\n",
            "Requirement already satisfied: python-dateutil>=2.6.1 in /usr/local/lib/python3.7/dist-packages (from wandb) (2.8.2)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.7/dist-packages (from GitPython>=1.0.0->wandb) (4.0.9)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from GitPython>=1.0.0->wandb) (3.10.0.2)\n",
            "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.7/dist-packages (from gitdb<5,>=4.0.1->GitPython>=1.0.0->wandb) (5.0.0)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.0.0->wandb) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.0.0->wandb) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.0.0->wandb) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.0.0->wandb) (2021.10.8)\n",
            "Requirement already satisfied: termcolor<2.0.0,>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from yaspin>=1.0.0->wandb) (1.1.0)\n"
          ]
        }
      ],
      "source": [
        "# installing necessary libraries\n",
        "\n",
        "!pip install torchtext==0.8.0 torch==1.7.1 pytorch-lightning==1.2.2\n",
        "!pip install transformers==4.5.0 --quiet\n",
        "!pip install wandb\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!wandb login"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "55fg7wDDkAzP",
        "outputId": "157c77d1-6a08-4a5a-a25f-7926e88262b6"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Paste an API key from your profile and hit enter, or press ctrl+c to quit: \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install optuna"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lmkCD7PirW0u",
        "outputId": "128274cd-c4a6-497d-bada-ba8f7095e39f"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting optuna\n",
            "  Downloading optuna-2.10.0-py3-none-any.whl (308 kB)\n",
            "\u001b[K     |████████████████████████████████| 308 kB 5.1 MB/s \n",
            "\u001b[?25hCollecting cliff\n",
            "  Downloading cliff-3.10.0-py3-none-any.whl (80 kB)\n",
            "\u001b[K     |████████████████████████████████| 80 kB 9.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: PyYAML in /usr/local/lib/python3.7/dist-packages (from optuna) (6.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from optuna) (4.62.3)\n",
            "Requirement already satisfied: sqlalchemy>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from optuna) (1.4.27)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from optuna) (1.19.5)\n",
            "Collecting cmaes>=0.8.2\n",
            "  Downloading cmaes-0.8.2-py3-none-any.whl (15 kB)\n",
            "Requirement already satisfied: scipy!=1.4.0 in /usr/local/lib/python3.7/dist-packages (from optuna) (1.4.1)\n",
            "Collecting alembic\n",
            "  Downloading alembic-1.7.5-py3-none-any.whl (209 kB)\n",
            "\u001b[K     |████████████████████████████████| 209 kB 38.1 MB/s \n",
            "\u001b[?25hCollecting colorlog\n",
            "  Downloading colorlog-6.6.0-py2.py3-none-any.whl (11 kB)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from optuna) (21.3)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->optuna) (3.0.6)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.7/dist-packages (from sqlalchemy>=1.1.0->optuna) (1.1.2)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from sqlalchemy>=1.1.0->optuna) (4.8.2)\n",
            "Requirement already satisfied: importlib-resources in /usr/local/lib/python3.7/dist-packages (from alembic->optuna) (5.4.0)\n",
            "Collecting Mako\n",
            "  Downloading Mako-1.1.6-py2.py3-none-any.whl (75 kB)\n",
            "\u001b[K     |████████████████████████████████| 75 kB 4.5 MB/s \n",
            "\u001b[?25hRequirement already satisfied: PrettyTable>=0.7.2 in /usr/local/lib/python3.7/dist-packages (from cliff->optuna) (2.4.0)\n",
            "Collecting pbr!=2.1.0,>=2.0.0\n",
            "  Downloading pbr-5.8.0-py2.py3-none-any.whl (112 kB)\n",
            "\u001b[K     |████████████████████████████████| 112 kB 44.4 MB/s \n",
            "\u001b[?25hCollecting cmd2>=1.0.0\n",
            "  Downloading cmd2-2.3.3-py3-none-any.whl (149 kB)\n",
            "\u001b[K     |████████████████████████████████| 149 kB 46.4 MB/s \n",
            "\u001b[?25hCollecting stevedore>=2.0.1\n",
            "  Downloading stevedore-3.5.0-py3-none-any.whl (49 kB)\n",
            "\u001b[K     |████████████████████████████████| 49 kB 5.8 MB/s \n",
            "\u001b[?25hCollecting autopage>=0.4.0\n",
            "  Downloading autopage-0.4.0-py3-none-any.whl (20 kB)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from cmd2>=1.0.0->cliff->optuna) (3.10.0.2)\n",
            "Collecting pyperclip>=1.6\n",
            "  Downloading pyperclip-1.8.2.tar.gz (20 kB)\n",
            "Requirement already satisfied: attrs>=16.3.0 in /usr/local/lib/python3.7/dist-packages (from cmd2>=1.0.0->cliff->optuna) (21.2.0)\n",
            "Requirement already satisfied: wcwidth>=0.1.7 in /usr/local/lib/python3.7/dist-packages (from cmd2>=1.0.0->cliff->optuna) (0.2.5)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->sqlalchemy>=1.1.0->optuna) (3.6.0)\n",
            "Requirement already satisfied: MarkupSafe>=0.9.2 in /usr/local/lib/python3.7/dist-packages (from Mako->alembic->optuna) (2.0.1)\n",
            "Building wheels for collected packages: pyperclip\n",
            "  Building wheel for pyperclip (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyperclip: filename=pyperclip-1.8.2-py3-none-any.whl size=11136 sha256=202864e485aaa54d98134e8edf15428b1220e72dffe255a89d48bc37b747fba8\n",
            "  Stored in directory: /root/.cache/pip/wheels/9f/18/84/8f69f8b08169c7bae2dde6bd7daf0c19fca8c8e500ee620a28\n",
            "Successfully built pyperclip\n",
            "Installing collected packages: pyperclip, pbr, stevedore, Mako, cmd2, autopage, colorlog, cmaes, cliff, alembic, optuna\n",
            "Successfully installed Mako-1.1.6 alembic-1.7.5 autopage-0.4.0 cliff-3.10.0 cmaes-0.8.2 cmd2-2.3.3 colorlog-6.6.0 optuna-2.10.0 pbr-5.8.0 pyperclip-1.8.2 stevedore-3.5.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LlsLnr1hVB3P",
        "outputId": "44153a8a-bf13-4c20-badc-7d739bfeb75b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Global seed set to 42\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "42"
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "from tqdm.auto import tqdm\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "from transformers import BertTokenizerFast as BertTokenizer, BertModel, AdamW, get_linear_schedule_with_warmup\n",
        "\n",
        "import pytorch_lightning as pl\n",
        "from pytorch_lightning.metrics.functional import accuracy\n",
        "from pytorch_lightning.callbacks import ModelCheckpoint, EarlyStopping\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "from pytorch_lightning.loggers import WandbLogger\n",
        "from pytorch_lightning import Trainer\n",
        "\n",
        "import optuna\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "%matplotlib inline\n",
        "RANDOM_SEED = 42\n",
        "\n",
        "pl.seed_everything(RANDOM_SEED)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "Cqwf4FrHVUF2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ed88b27b-ad06-4009-ebad-ea167b4721c0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1VuQ-U7TtggShMeuRSA_hzC8qGDl2LRkr\n",
            "To: /content/toxic_comments.csv\n",
            "100% 68.8M/68.8M [00:00<00:00, 111MB/s] \n"
          ]
        }
      ],
      "source": [
        "!gdown --id 1VuQ-U7TtggShMeuRSA_hzC8qGDl2LRkr"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "sejAHXLEYj3H",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "outputId": "30959999-6a70-4c1f-fa17-60301bc85b90"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-80837032-ae42-48bb-8403-eb5eaf1c14c1\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>comment_text</th>\n",
              "      <th>toxic</th>\n",
              "      <th>severe_toxic</th>\n",
              "      <th>obscene</th>\n",
              "      <th>threat</th>\n",
              "      <th>insult</th>\n",
              "      <th>identity_hate</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0000997932d777bf</td>\n",
              "      <td>Explanation\\nWhy the edits made under my usern...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>000103f0d9cfb60f</td>\n",
              "      <td>D'aww! He matches this background colour I'm s...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>000113f07ec002fd</td>\n",
              "      <td>Hey man, I'm really not trying to edit war. It...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0001b41b1c6bb37e</td>\n",
              "      <td>\"\\nMore\\nI can't make any real suggestions on ...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0001d958c54c6e35</td>\n",
              "      <td>You, sir, are my hero. Any chance you remember...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-80837032-ae42-48bb-8403-eb5eaf1c14c1')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-80837032-ae42-48bb-8403-eb5eaf1c14c1 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-80837032-ae42-48bb-8403-eb5eaf1c14c1');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "                 id  ... identity_hate\n",
              "0  0000997932d777bf  ...             0\n",
              "1  000103f0d9cfb60f  ...             0\n",
              "2  000113f07ec002fd  ...             0\n",
              "3  0001b41b1c6bb37e  ...             0\n",
              "4  0001d958c54c6e35  ...             0\n",
              "\n",
              "[5 rows x 8 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ],
      "source": [
        "df = pd.read_csv(\"toxic_comments.csv\")\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oeGV3jola0TY"
      },
      "source": [
        "# **Part 2: Exploratory Data Analysis**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "EoQOSD3Qa6WN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "411f3199-920f-4cc5-a1fa-44f5501683c1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of examples in the dataset 159571\n",
            "Number of classes in the dataset 6\n",
            "Number of toxic examples in the dataset: 15294\n",
            "Number of severe_toxic examples in the dataset: 1595\n",
            "Number of obscene examples in the dataset: 8449\n",
            "Number of threat examples in the dataset: 478\n",
            "Number of insult examples in the dataset: 7877\n",
            "Number of identity_hate examples in the dataset: 1405\n",
            "Number of good examples in the dataset 143346\n"
          ]
        }
      ],
      "source": [
        "# Total comments\n",
        "print(f'Number of examples in the dataset {len(df)}')\n",
        "\n",
        "classes=df.columns.tolist()[2:]\n",
        "\n",
        "print(f'Number of classes in the dataset {len(classes)}')\n",
        "\n",
        "# Total examples of each class\n",
        "for class_ in classes:\n",
        "  print(f'Number of {class_} examples in the dataset: {len(df[df[class_]==1])}')\n",
        "\n",
        "\n",
        "# Total good comments (none of the above classes)\n",
        "print(f'Number of good examples in the dataset {len(df[df[classes].sum(axis=1) == 0])}')\n",
        "\n",
        "\n",
        "TARGET_CLASSES=classes\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "EVf03YNYbSbb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9c3b56ea-4b69-4500-a41c-981e1d63fcde"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((151592, 8), (7979, 8))"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ],
      "source": [
        "train_df, val_df = train_test_split(df, test_size=0.05)\n",
        "train_df.shape, val_df.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "ORiKfxZXgCYv",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "outputId": "54a6d383-5026-4113-c49a-8053091427f3"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "train_toxic = train_df[train_df[classes].sum(axis=1) > 0]\n",
        "train_clean = train_df[train_df[classes].sum(axis=1) == 0]\n",
        "\n",
        "pd.DataFrame(dict(\n",
        "  toxic=[len(train_toxic)], \n",
        "  good=[len(train_clean)]\n",
        ")).plot(kind='barh');"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "d7L5tvk8gG40",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0d34d65b-447c-4973-dfab-7b980cb457f3"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((30427, 8), (7979, 8))"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ],
      "source": [
        "# Undersampling good comments\n",
        "train_df = pd.concat([\n",
        "  train_toxic,\n",
        "  train_clean.sample(15_000)\n",
        "])\n",
        "\n",
        "train_df.shape, val_df.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l4cCTEDyhTQg"
      },
      "source": [
        "# **Pre-processing**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "qbQ0H38JhQwy"
      },
      "outputs": [],
      "source": [
        "BERT_MODEL_NAME = 'bert-base-cased'\n",
        "tokenizer = BertTokenizer.from_pretrained(BERT_MODEL_NAME)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "zbtX1WQ_ila2"
      },
      "outputs": [],
      "source": [
        "token_counts = []\n",
        "\n",
        "for _, row in train_df.iterrows():\n",
        "  token_count = len(tokenizer.encode(\n",
        "    row[\"comment_text\"], \n",
        "    truncation=True\n",
        "  ))\n",
        "  token_counts.append(token_count)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "WebtJw-nivwb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ad9efead-e43d-4e8c-b661-0201c2d617a6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "lengthiest comment's size: 512\n"
          ]
        }
      ],
      "source": [
        "print(f'lengthiest comment\\'s size: {max(token_counts)}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "KYhYI-V9i-Np"
      },
      "outputs": [],
      "source": [
        "MAX_LENGTH=max(token_counts)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JYg6T9mLjzYU"
      },
      "source": [
        "# **Dataset class**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "gjkOzxB7j4BS"
      },
      "outputs": [],
      "source": [
        "# Built upon Dataset module that tokenizes data and returns\n",
        "class ToxicCommentsDataset(Dataset):\n",
        "\n",
        "  def __init__(self, data: pd.DataFrame, tokenizer: BertTokenizer, max_token_len: int = 512):\n",
        "    self.tokenizer = tokenizer\n",
        "    self.data = data\n",
        "    self.max_token_len = max_token_len\n",
        "    \n",
        "  def __len__(self):\n",
        "    return len(self.data)\n",
        "\n",
        "  def __getitem__(self, index: int):\n",
        "    data_row = self.data.iloc[index]\n",
        "\n",
        "    comment_text = data_row.comment_text\n",
        "    labels = data_row[TARGET_CLASSES]\n",
        "\n",
        "    encoding = self.tokenizer.encode_plus(\n",
        "      comment_text,\n",
        "      add_special_tokens=True,\n",
        "      max_length=self.max_token_len,\n",
        "      return_token_type_ids=False,\n",
        "      padding=\"max_length\",\n",
        "      truncation=True,\n",
        "      return_attention_mask=True,\n",
        "      return_tensors='pt',\n",
        "    )\n",
        "\n",
        "    return dict(\n",
        "      comment_text=comment_text,\n",
        "      input_ids=encoding[\"input_ids\"].flatten(),\n",
        "      attention_mask=encoding[\"attention_mask\"].flatten(),\n",
        "      labels=torch.FloatTensor(labels)\n",
        "    )"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the dataset using dataset loader\n",
        "train_dataset = ToxicCommentsDataset(\n",
        "  train_df,\n",
        "  tokenizer,\n",
        "  max_token_len=MAX_LENGTH\n",
        ")\n",
        "\n",
        "# sample_item = train_dataset[0]\n",
        "# sample_item.keys()"
      ],
      "metadata": {
        "id": "YQDu1YGmXDND"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "kQGPvPPYFaON",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "efe24473-cf8c-4db7-d505-188d3d1dfa81"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.Size([8, 512]), torch.Size([8, 512]))"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ],
      "source": [
        "sample_batch = next(iter(DataLoader(train_dataset, batch_size=8, num_workers=2)))\n",
        "sample_batch[\"input_ids\"].shape, sample_batch[\"attention_mask\"].shape"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Data module using Lightning data module\n",
        "\n",
        "class ToxicCommentDataModule(pl.LightningDataModule):\n",
        "\n",
        "  def __init__(self, train_df, test_df, tokenizer, batch_size=8, max_token_len=128):\n",
        "    super().__init__()\n",
        "    self.batch_size = batch_size\n",
        "    self.train_df = train_df\n",
        "    self.test_df = test_df\n",
        "    self.tokenizer = tokenizer\n",
        "    self.max_token_len = max_token_len\n",
        "\n",
        "  def setup(self, stage=None):\n",
        "    self.train_dataset = ToxicCommentsDataset(\n",
        "      self.train_df,\n",
        "      self.tokenizer,\n",
        "      self.max_token_len\n",
        "    )\n",
        "\n",
        "    self.test_dataset = ToxicCommentsDataset(\n",
        "      self.test_df,\n",
        "      self.tokenizer,\n",
        "      self.max_token_len\n",
        "    )\n",
        "\n",
        "  def train_dataloader(self):\n",
        "    return DataLoader(\n",
        "      self.train_dataset,\n",
        "      batch_size=self.batch_size,\n",
        "      shuffle=True,\n",
        "      num_workers=2\n",
        "    )\n",
        "\n",
        "  def val_dataloader(self):\n",
        "    return DataLoader(\n",
        "      self.test_dataset,\n",
        "      batch_size=self.batch_size,\n",
        "      num_workers=2\n",
        "    )\n",
        "\n",
        "  def test_dataloader(self):\n",
        "    return DataLoader(\n",
        "      self.test_dataset,\n",
        "      batch_size=self.batch_size,\n",
        "      num_workers=2\n",
        "    )"
      ],
      "metadata": {
        "id": "FTM4dMgBXRkq"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "N_EPOCHS = 10\n",
        "BATCH_SIZE = 12\n",
        "\n",
        "# All data loading logic\n",
        "data_module = ToxicCommentDataModule(\n",
        "  train_df,\n",
        "  val_df,\n",
        "  tokenizer,\n",
        "  batch_size=BATCH_SIZE,\n",
        "  max_token_len=MAX_LENGTH\n",
        ")"
      ],
      "metadata": {
        "id": "yvnkjeLnYJs5"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **The BERT model**"
      ],
      "metadata": {
        "id": "TB1IxS09YoMt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# bert_model = BertModel.from_pretrained(BERT_MODEL_NAME, return_dict=True)\n",
        "# bert_model"
      ],
      "metadata": {
        "id": "oLOhZQCkY55S"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Custom model bert + a layer to classify - using lightning module\n",
        "\n",
        "class ToxicCommentTagger(pl.LightningModule):\n",
        "\n",
        "  def __init__(self, n_classes: int, n_training_steps=None, n_warmup_steps=None,learning_rate=1e-5):\n",
        "    super().__init__()\n",
        "    self.bert = BertModel.from_pretrained(BERT_MODEL_NAME, return_dict=True)\n",
        "    self.classifier = nn.Linear(self.bert.config.hidden_size, n_classes)\n",
        "    self.n_training_steps = n_training_steps\n",
        "    self.n_warmup_steps = n_warmup_steps\n",
        "    self.learning_rate=learning_rate\n",
        "    self.criterion = nn.BCELoss()\n",
        "\n",
        "  def forward(self, input_ids, attention_mask, labels=None):\n",
        "    output = self.bert(input_ids, attention_mask=attention_mask)\n",
        "    output = self.classifier(output.pooler_output)\n",
        "    output = torch.sigmoid(output)    \n",
        "    loss = 0\n",
        "    if labels is not None:\n",
        "        loss = self.criterion(output, labels)\n",
        "    return loss, output\n",
        "\n",
        "  def training_step(self, batch, batch_idx):\n",
        "    input_ids = batch[\"input_ids\"]\n",
        "    attention_mask = batch[\"attention_mask\"]\n",
        "    labels = batch[\"labels\"]\n",
        "    loss, outputs = self(input_ids, attention_mask, labels)\n",
        "    self.log(\"train_loss\", loss, prog_bar=True, logger=True)\n",
        "    return {\"loss\": loss, \"predictions\": outputs, \"labels\": labels}\n",
        "\n",
        "  def validation_step(self, batch, batch_idx):\n",
        "    input_ids = batch[\"input_ids\"]\n",
        "    attention_mask = batch[\"attention_mask\"]\n",
        "    labels = batch[\"labels\"]\n",
        "    loss, outputs = self(input_ids, attention_mask, labels)\n",
        "    self.log(\"val_loss\", loss, prog_bar=True, logger=True)\n",
        "    return loss\n",
        "\n",
        "  def test_step(self, batch, batch_idx):\n",
        "    input_ids = batch[\"input_ids\"]\n",
        "    attention_mask = batch[\"attention_mask\"]\n",
        "    labels = batch[\"labels\"]\n",
        "    loss, outputs = self(input_ids, attention_mask, labels)\n",
        "    self.log(\"test_loss\", loss, prog_bar=True, logger=True)\n",
        "    return loss\n",
        "\n",
        "  def training_epoch_end(self, outputs):\n",
        "    \n",
        "    labels = []\n",
        "    predictions = []\n",
        "    for output in outputs:\n",
        "      for out_labels in output[\"labels\"].detach().cpu():\n",
        "        labels.append(out_labels)\n",
        "      for out_predictions in output[\"predictions\"].detach().cpu():\n",
        "        predictions.append(out_predictions)\n",
        "\n",
        "    labels = torch.stack(labels).int()\n",
        "    predictions = torch.stack(predictions)\n",
        "\n",
        "    self.log('train_acc_epoch', accuracy(predictions, labels, threshold=0.5).item(),prog_bar=True, logger=True)\n",
        "\n",
        "  def configure_optimizers(self):\n",
        "\n",
        "    optimizer = AdamW(self.parameters(), lr=self.learning_rate)\n",
        "\n",
        "    scheduler = get_linear_schedule_with_warmup(\n",
        "      optimizer,\n",
        "      num_warmup_steps=self.n_warmup_steps,\n",
        "      num_training_steps=self.n_training_steps\n",
        "    )\n",
        "\n",
        "    return dict(\n",
        "      optimizer=optimizer,\n",
        "      lr_scheduler=dict(\n",
        "        scheduler=scheduler,\n",
        "        interval='step'\n",
        "      )\n",
        "    )"
      ],
      "metadata": {
        "id": "tXi94eNXYZmL"
      },
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "steps_per_epoch=len(train_df) // BATCH_SIZE\n",
        "total_training_steps = steps_per_epoch * N_EPOCHS\n",
        "warmup_steps = total_training_steps // 5\n",
        "warmup_steps, total_training_steps"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QAZu6OV1alFj",
        "outputId": "c8fb90e1-1361-4713-f268-4a0648775bcf"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(5070, 25350)"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = ToxicCommentTagger(\n",
        "  n_classes=len(TARGET_CLASSES),\n",
        "  n_warmup_steps=warmup_steps,\n",
        "  n_training_steps=total_training_steps,\n",
        "  learning_rate=2e-5 \n",
        ")"
      ],
      "metadata": {
        "id": "hqJJSgaFbGBl"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Training**"
      ],
      "metadata": {
        "id": "KiP7Aer1btTj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "checkpoint_callback = ModelCheckpoint(\n",
        "  dirpath=\"checkpoints\",\n",
        "  filename=\"best-checkpoint\",\n",
        "  save_top_k=1,\n",
        "  verbose=True,\n",
        "  monitor=\"val_loss\",\n",
        "  mode=\"min\"\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wu0sOobzbyTl",
        "outputId": "c43648c8-609f-46c1-866b-6ee24a2fca08"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/distributed.py:50: UserWarning: Checkpoint directory checkpoints exists and is not empty.\n",
            "  warnings.warn(*args, **kwargs)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Using wandb logger\n",
        "wandb_logger = WandbLogger(project=\"toxic-comments\")"
      ],
      "metadata": {
        "id": "YxhyvbhwcA6h"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "early_stopping_callback = EarlyStopping(monitor='val_loss', patience=2)"
      ],
      "metadata": {
        "id": "eLMyyBxbcCbz"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trainer = pl.Trainer(\n",
        "  logger=wandb_logger,\n",
        "  checkpoint_callback=checkpoint_callback,\n",
        "  callbacks=[early_stopping_callback],\n",
        "  max_epochs=N_EPOCHS,\n",
        "  gpus=1,\n",
        "  progress_bar_refresh_rate=30\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7IoK094mcEXc",
        "outputId": "93d53946-ec1c-4c05-f931-d6f8ed761bc7"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "GPU available: True, used: True\n",
            "TPU available: None, using: 0 TPU cores\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Uncomment to re-train the model\n",
        "# trainer.fit(model, data_module)"
      ],
      "metadata": {
        "id": "gaINMoMwcGDC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Loading the saved model\n",
        "trained_model = ToxicCommentTagger.load_from_checkpoint(\n",
        "  # trainer.checkpoint_callback.best_model_path, \n",
        "  'checkpoints/best-checkpoint.ckpt', # using saved model\n",
        "  n_classes=len(TARGET_CLASSES)\n",
        ")\n",
        "trained_model.eval()\n",
        "trained_model.freeze()\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "trained_model = trained_model.to(device)"
      ],
      "metadata": {
        "id": "2lTJL36YcPQG"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "THRESHOLD = 0.5\n",
        "\n",
        "test_comment = \"You are such a bitch!!\"\n",
        "encoding = tokenizer.encode_plus(\n",
        "  test_comment,\n",
        "  add_special_tokens=True,\n",
        "  max_length=512,\n",
        "  return_token_type_ids=False,\n",
        "  padding=\"max_length\",\n",
        "  return_attention_mask=True,\n",
        "  return_tensors='pt',\n",
        ")\n",
        "\n",
        "_, test_prediction = trained_model(encoding[\"input_ids\"].to(device), encoding[\"attention_mask\"].to(device))\n",
        "test_prediction = test_prediction.flatten().cpu().data.numpy()\n",
        "\n",
        "for label, prediction in zip(TARGET_CLASSES, test_prediction):\n",
        "  if prediction < THRESHOLD:\n",
        "    continue\n",
        "  print(f\"{label}: {prediction}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T6oyrxe_cwqD",
        "outputId": "a7117e3d-4f9c-43d8-ce03-c3248084612c"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "toxic: 0.9972378015518188\n",
            "obscene: 0.989346444606781\n",
            "insult: 0.9757869243621826\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "val_dataset = ToxicCommentsDataset(\n",
        "  val_df,\n",
        "  tokenizer,\n",
        "  max_token_len=MAX_LENGTH\n",
        ")\n",
        "\n",
        "predictions = []\n",
        "labels = []\n",
        "\n",
        "for item in tqdm(val_dataset):\n",
        "  _, prediction = trained_model(\n",
        "    item[\"input_ids\"].unsqueeze(dim=0).to(device), \n",
        "    item[\"attention_mask\"].unsqueeze(dim=0).to(device)\n",
        "  )\n",
        "  predictions.append(prediction.flatten())\n",
        "  labels.append(item[\"labels\"].int())\n",
        "\n",
        "predictions = torch.stack(predictions).detach().cpu()\n",
        "labels = torch.stack(labels).detach().cpu()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49,
          "referenced_widgets": [
            "05a438df3a554a19ac0d10b1bb99e691",
            "4ff66dcc9d3a4fe1aedd6f7d8a56a7bf",
            "168e10e740c94fa4a9fb939e280a3e99",
            "12b5d06bb6b349a984db3dfc31ecedb9",
            "85821af795c3495181825e81ba85769f",
            "f77af8fd5711427284f65fed61f19d50",
            "0df4a9a8bdbd4c27a9832db084079313",
            "1217808f6e4a446f826e4a1f3b21f2f1",
            "4f4d5fc96c46441b95456128910170bf",
            "22460d3615df44bab3f63c99ffcb7ebe",
            "43404968229f43abb3658254b220531f"
          ]
        },
        "id": "m22S2l26ddeU",
        "outputId": "db6ceb34-e851-4dca-a135-82af035e7d86"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "05a438df3a554a19ac0d10b1bb99e691",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "  0%|          | 0/7979 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(f'accuracy is : {accuracy(predictions, labels, threshold=THRESHOLD).item()}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Zr9GRMkNdfzD",
        "outputId": "c1aa7afa-7c4f-466a-bbfa-1d3607ee3ba6"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "accuracy is : 0.982077956199646\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def hpoptimize(model):\n",
        "  def get_accuracy(model):\n",
        "    val_dataset = ToxicCommentsDataset(\n",
        "                  val_df,\n",
        "                  tokenizer,\n",
        "                  max_token_len=MAX_LENGTH\n",
        "                )\n",
        "\n",
        "    predictions = []\n",
        "    labels = []\n",
        "    i=0\n",
        "    for item in tqdm(val_dataset):\n",
        "      _, prediction = model(\n",
        "        item[\"input_ids\"].unsqueeze(dim=0), \n",
        "        item[\"attention_mask\"].unsqueeze(dim=0)\n",
        "      )\n",
        "      predictions.append(prediction.flatten())\n",
        "      labels.append(item[\"labels\"].int())\n",
        "      i+=1\n",
        "      if i==1000:\n",
        "        break\n",
        "\n",
        "    predictions = torch.stack(predictions)\n",
        "    labels = torch.stack(labels)\n",
        "    return accuracy(predictions, labels, threshold=THRESHOLD).item()\n",
        "\n",
        "  def objective(trial):\n",
        "    params={\n",
        "        'learning_rate':trial.suggest_loguniform(\"learning_rate\",1e-6,1e-3)\n",
        "    }\n",
        "    model = ToxicCommentTagger(\n",
        "      n_classes=len(TARGET_CLASSES),\n",
        "      n_warmup_steps=len(train_df)*N_EPOCHS//5,\n",
        "      n_training_steps=len(train_df)*N_EPOCHS,\n",
        "      learning_rate=params['learning_rate'] \n",
        "    )\n",
        "    trainer.fit(model, data_module)\n",
        "    return get_accuracy(model)\n",
        "\n",
        "  study=optuna.create_study(direction='maximize')\n",
        "  study.optimize(objective,n_trials=10)\n",
        "  print(f'best trial: {study.best_trial}')\n",
        "  return ToxicCommentTagger(\n",
        "      n_classes=len(TARGET_CLASSES),\n",
        "      n_warmup_steps=len(train_df)*N_EPOCHS//5,\n",
        "      n_training_steps=len(train_df)*N_EPOCHS,\n",
        "      learning_rate=study.best_trial.params['learning_rate'] \n",
        "    )\n",
        "\n",
        "  \n",
        "\n",
        "\n",
        "  \n",
        "\n",
        "  \n",
        "\n"
      ],
      "metadata": {
        "id": "qkKVTnQhfrUx"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Get the best model after hpoptimization\n",
        "N_EPOCHS=2\n",
        "trained_model=hpoptimize(trained_model)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 200
        },
        "id": "vaS1LU5nsjTH",
        "outputId": "da43f3c5-25fa-450d-cdce-21cbd11bcb88"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-4-b79115d3aff1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Get the best model after hpoptimization\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mN_EPOCHS\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mtrained_model\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mhpoptimize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrained_model\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'trained_model' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "N_EPOCHS=10"
      ],
      "metadata": {
        "id": "Trv9NMDYs4Vm"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "toxic-comment-classification.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyNTPUwZKftn4cMx4IIdJuYD",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "05a438df3a554a19ac0d10b1bb99e691": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_4ff66dcc9d3a4fe1aedd6f7d8a56a7bf",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_168e10e740c94fa4a9fb939e280a3e99",
              "IPY_MODEL_12b5d06bb6b349a984db3dfc31ecedb9",
              "IPY_MODEL_85821af795c3495181825e81ba85769f"
            ]
          }
        },
        "4ff66dcc9d3a4fe1aedd6f7d8a56a7bf": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "168e10e740c94fa4a9fb939e280a3e99": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_f77af8fd5711427284f65fed61f19d50",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "100%",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_0df4a9a8bdbd4c27a9832db084079313"
          }
        },
        "12b5d06bb6b349a984db3dfc31ecedb9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_1217808f6e4a446f826e4a1f3b21f2f1",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 7979,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 7979,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_4f4d5fc96c46441b95456128910170bf"
          }
        },
        "85821af795c3495181825e81ba85769f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_22460d3615df44bab3f63c99ffcb7ebe",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 7979/7979 [10:02&lt;00:00, 12.89it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_43404968229f43abb3658254b220531f"
          }
        },
        "f77af8fd5711427284f65fed61f19d50": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "0df4a9a8bdbd4c27a9832db084079313": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "1217808f6e4a446f826e4a1f3b21f2f1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "4f4d5fc96c46441b95456128910170bf": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "22460d3615df44bab3f63c99ffcb7ebe": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "43404968229f43abb3658254b220531f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}